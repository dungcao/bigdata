{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ce0ca95",
   "metadata": {},
   "source": [
    "### Exit SPARK_HOME and run the follow command before staring jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9407a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export SPARK_HOME=/Users/Storage/Soft/spark-3.0.1-bin-hadoop3.2\n",
    "# export PYSPARK_PYTHON=python3\n",
    "# export PYTHONPATH=$SPARK_HOME/python:$SPARK_HOME/python/lib/py4j-0.10.9-src.zip:$PYTHONPATH\n",
    "# export PATH=$SPARK_HOME/bin:$SPARK_HOME/python:$PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e699293",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, lit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "367f63f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType,IntegerType, DoubleType,BooleanType\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b93f927b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/04/24 16:11:44 WARN Utils: Your hostname, Dungs-MacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.10.25 instead (on interface en0)\n",
      "23/04/24 16:11:44 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/04/24 16:12:15 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession \\\n",
    "            .builder \\\n",
    "            .master(\"local[1]\") \\\n",
    "            .appName('dungcao.com') \\\n",
    "            .getOrCreate()\n",
    "#             .config(\"spark.jars\", \"/Users/Storage/Soft/mysql-connector-java-8.0.30.jar\") \\\n",
    "\n",
    "spark.sparkContext.setLogLevel('ERROR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "055af67e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyspark.sql.session.SparkSession object at 0x105942940>\n"
     ]
    }
   ],
   "source": [
    "print(spark)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df95e478",
   "metadata": {},
   "source": [
    "## 1. Create DataFrame from Python list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85355f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- first_name: string (nullable = true)\n",
      " |-- middle_name: string (nullable = true)\n",
      " |-- last_name: string (nullable = true)\n",
      " |-- dob: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: long (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+---------+-----+------+------+\n",
      "|first_name|middle_name|last_name|dob  |gender|salary|\n",
      "+----------+-----------+---------+-----+------+------+\n",
      "|James     |           |Smith    |36636|M     |60000 |\n",
      "|Michael   |Rose       |         |40288|M     |70000 |\n",
      "|Robert    |           |Williams |42114|      |400000|\n",
      "|Maria     |Anne       |Jones    |39192|F     |500000|\n",
      "|Jen       |Mary       |Brown    |     |F     |0     |\n",
      "+----------+-----------+---------+-----+------+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "data = [(\"James\",\"\",\"Smith\",\"36636\",\"M\",60000),\n",
    "        (\"Michael\",\"Rose\",\"\",\"40288\",\"M\",70000),\n",
    "        (\"Robert\",\"\",\"Williams\",\"42114\",\"\",400000),\n",
    "        (\"Maria\",\"Anne\",\"Jones\",\"39192\",\"F\",500000),\n",
    "        (\"Jen\",\"Mary\",\"Brown\",\"\",\"F\",0)]\n",
    "\n",
    "columns = [\"first_name\",\"middle_name\",\"last_name\",\"dob\",\"gender\",\"salary\"]\n",
    "pysparkDF = spark.createDataFrame(data = data, schema = columns)\n",
    "pysparkDF.printSchema()\n",
    "pysparkDF.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aab59fc",
   "metadata": {},
   "source": [
    "##### Nested Structure Elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bfe257b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: struct (nullable = true)\n",
      " |    |-- firstname: string (nullable = true)\n",
      " |    |-- middlename: string (nullable = true)\n",
      " |    |-- lastname: string (nullable = true)\n",
      " |-- dob: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: string (nullable = true)\n",
      "\n",
      "+--------------------+-----+------+------+\n",
      "|name                |dob  |gender|salary|\n",
      "+--------------------+-----+------+------+\n",
      "|[James, , Smith]    |36636|M     |3000  |\n",
      "|[Michael, Rose, ]   |40288|M     |4000  |\n",
      "|[Robert, , Williams]|42114|M     |4000  |\n",
      "|[Maria, Anne, Jones]|39192|F     |4000  |\n",
      "|[Jen, Mary, Brown]  |     |F     |-1    |\n",
      "+--------------------+-----+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataStruct = [((\"James\",\"\",\"Smith\"),\"36636\",\"M\",\"3000\"), \\\n",
    "      ((\"Michael\",\"Rose\",\"\"),\"40288\",\"M\",\"4000\"), \\\n",
    "      ((\"Robert\",\"\",\"Williams\"),\"42114\",\"M\",\"4000\"), \\\n",
    "      ((\"Maria\",\"Anne\",\"Jones\"),\"39192\",\"F\",\"4000\"), \\\n",
    "      ((\"Jen\",\"Mary\",\"Brown\"),\"\",\"F\",\"-1\") \\\n",
    "]\n",
    "\n",
    "schemaStruct = StructType([\n",
    "        StructField('name', StructType([\n",
    "             StructField('firstname', StringType(), True),\n",
    "             StructField('middlename', StringType(), True),\n",
    "             StructField('lastname', StringType(), True)\n",
    "             ])),\n",
    "          StructField('dob', StringType(), True),\n",
    "         StructField('gender', StringType(), True),\n",
    "         StructField('salary', StringType(), True)\n",
    "         ])\n",
    "\n",
    "\n",
    "df = spark.createDataFrame(data=dataStruct, schema = schemaStruct)\n",
    "df.printSchema()\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e088d36f",
   "metadata": {},
   "source": [
    "### 2. Read from text file (csv, json,...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4367725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- club: string (nullable = true)\n",
      " |-- age: string (nullable = true)\n",
      " |-- position: string (nullable = true)\n",
      " |-- position_cat: string (nullable = true)\n",
      " |-- market_value: string (nullable = true)\n",
      " |-- page_views: string (nullable = true)\n",
      " |-- fpl_value: string (nullable = true)\n",
      " |-- fpl_sel: string (nullable = true)\n",
      " |-- fpl_points: string (nullable = true)\n",
      " |-- region: string (nullable = true)\n",
      " |-- nationality: string (nullable = true)\n",
      " |-- new_foreign: string (nullable = true)\n",
      " |-- age_cat: string (nullable = true)\n",
      " |-- club_id: string (nullable = true)\n",
      " |-- big_club: string (nullable = true)\n",
      " |-- new_signing: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2 = spark.read.option(\"header\",True) \\\n",
    "     .csv(\"/Users/Storage/OtherTeaching/Python/practice/epldata_final.csv\")\n",
    "df2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b237cda5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------+---+--------+------------+------------+----------+---------+-------+----------+------+--------------+-----------+-------+-------+--------+-----------+\n",
      "|             name|   club|age|position|position_cat|market_value|page_views|fpl_value|fpl_sel|fpl_points|region|   nationality|new_foreign|age_cat|club_id|big_club|new_signing|\n",
      "+-----------------+-------+---+--------+------------+------------+----------+---------+-------+----------+------+--------------+-----------+-------+-------+--------+-----------+\n",
      "|   Alexis Sanchez|Arsenal| 28|      LW|           1|          65|      4329|       12| 17.10%|       264|     3|         Chile|          0|      4|      1|       1|          0|\n",
      "|       Mesut Ozil|Arsenal| 28|      AM|           1|          50|      4395|      9.5|  5.60%|       167|     2|       Germany|          0|      4|      1|       1|          0|\n",
      "|        Petr Cech|Arsenal| 35|      GK|           4|           7|      1529|      5.5|  5.90%|       134|     2|Czech Republic|          0|      6|      1|       1|          0|\n",
      "|     Theo Walcott|Arsenal| 28|      RW|           1|          20|      2393|      7.5|  1.50%|       122|     1|       England|          0|      4|      1|       1|          0|\n",
      "|Laurent Koscielny|Arsenal| 31|      CB|           3|          22|       912|        6|  0.70%|       121|     2|        France|          0|      4|      1|       1|          0|\n",
      "+-----------------+-------+---+--------+------------+------------+----------+---------+-------+----------+------+--------------+-----------+-------+-------+--------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6aa2f9f",
   "metadata": {},
   "source": [
    "#### + Read with defined schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df415944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- RecordNumber: integer (nullable = true)\n",
      " |-- Zipcode: integer (nullable = true)\n",
      " |-- ZipCodeType: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- LocationType: string (nullable = true)\n",
      " |-- Lat: double (nullable = true)\n",
      " |-- Long: double (nullable = true)\n",
      " |-- Xaxis: integer (nullable = true)\n",
      " |-- Yaxis: double (nullable = true)\n",
      " |-- Zaxis: double (nullable = true)\n",
      " |-- WorldRegion: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- LocationText: string (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- Decommisioned: boolean (nullable = true)\n",
      " |-- TaxReturnsFiled: string (nullable = true)\n",
      " |-- EstimatedPopulation: integer (nullable = true)\n",
      " |-- TotalWages: integer (nullable = true)\n",
      " |-- Notes: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "schema = StructType() \\\n",
    "      .add(\"RecordNumber\",IntegerType(),True) \\\n",
    "      .add(\"Zipcode\",IntegerType(),True) \\\n",
    "      .add(\"ZipCodeType\",StringType(),True) \\\n",
    "      .add(\"City\",StringType(),True) \\\n",
    "      .add(\"State\",StringType(),True) \\\n",
    "      .add(\"LocationType\",StringType(),True) \\\n",
    "      .add(\"Lat\",DoubleType(),True) \\\n",
    "      .add(\"Long\",DoubleType(),True) \\\n",
    "      .add(\"Xaxis\",IntegerType(),True) \\\n",
    "      .add(\"Yaxis\",DoubleType(),True) \\\n",
    "      .add(\"Zaxis\",DoubleType(),True) \\\n",
    "      .add(\"WorldRegion\",StringType(),True) \\\n",
    "      .add(\"Country\",StringType(),True) \\\n",
    "      .add(\"LocationText\",StringType(),True) \\\n",
    "      .add(\"Location\",StringType(),True) \\\n",
    "      .add(\"Decommisioned\",BooleanType(),True) \\\n",
    "      .add(\"TaxReturnsFiled\",StringType(),True) \\\n",
    "      .add(\"EstimatedPopulation\",IntegerType(),True) \\\n",
    "      .add(\"TotalWages\",IntegerType(),True) \\\n",
    "      .add(\"Notes\",StringType(),True)\n",
    "      \n",
    "df_with_schema = spark.read.format(\"csv\") \\\n",
    "      .option(\"header\", True) \\\n",
    "      .schema(schema) \\\n",
    "      .load(\"/Users/Storage/OtherTeaching/Data/zipcodes.csv\")\n",
    "df_with_schema.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3762fb33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------+-----------+-------------------+-----+--------------+-----+------+-----+-----+-----+-----------+-------+--------------------+--------------------+-------------+---------------+-------------------+----------+-----+\n",
      "|RecordNumber|Zipcode|ZipCodeType|               City|State|  LocationType|  Lat|  Long|Xaxis|Yaxis|Zaxis|WorldRegion|Country|        LocationText|            Location|Decommisioned|TaxReturnsFiled|EstimatedPopulation|TotalWages|Notes|\n",
      "+------------+-------+-----------+-------------------+-----+--------------+-----+------+-----+-----+-----+-----------+-------+--------------------+--------------------+-------------+---------------+-------------------+----------+-----+\n",
      "|           1|    704|   STANDARD|        PARC PARQUE|   PR|NOT ACCEPTABLE|17.96|-66.22| null|-0.87|  0.3|         NA|     US|     Parc Parque, PR|NA-US-PR-PARC PARQUE|        false|           null|               null|      null| null|\n",
      "|           2|    704|   STANDARD|PASEO COSTA DEL SUR|   PR|NOT ACCEPTABLE|17.96|-66.22| null|-0.87|  0.3|         NA|     US|Paseo Costa Del S...|NA-US-PR-PASEO CO...|        false|           null|               null|      null| null|\n",
      "|          10|    709|   STANDARD|       BDA SAN LUIS|   PR|NOT ACCEPTABLE|18.14|-66.26| null|-0.86| 0.31|         NA|     US|    Bda San Luis, PR|NA-US-PR-BDA SAN ...|        false|           null|               null|      null| null|\n",
      "|       61391|  76166|     UNIQUE|  CINGULAR WIRELESS|   TX|NOT ACCEPTABLE|32.72|-97.31| null|-0.83| 0.54|         NA|     US|Cingular Wireless...|NA-US-TX-CINGULAR...|        false|           null|               null|      null| null|\n",
      "|       61392|  76177|   STANDARD|         FORT WORTH|   TX|       PRIMARY|32.75|-97.33| null|-0.83| 0.54|         NA|     US|      Fort Worth, TX| NA-US-TX-FORT WORTH|        false|           2126|               4053| 122396986| null|\n",
      "+------------+-------+-----------+-------------------+-----+--------------+-----+------+-----+-----+-----+-----------+-------+--------------------+--------------------+-------------+---------------+-------------------+----------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_with_schema.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b567a6",
   "metadata": {},
   "source": [
    "#### + Write dataframe to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d497f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_with_schema.write.option(\"header\",True).csv(\"local or hdfs path\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0a5294",
   "metadata": {},
   "source": [
    "#### + Read JSON "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "66806bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- RecordNumber: integer (nullable = true)\n",
      " |-- Zipcode: integer (nullable = true)\n",
      " |-- ZipCodeType: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- LocationType: string (nullable = true)\n",
      " |-- Lat: double (nullable = true)\n",
      " |-- Long: double (nullable = true)\n",
      " |-- Xaxis: integer (nullable = true)\n",
      " |-- Yaxis: double (nullable = true)\n",
      " |-- Zaxis: double (nullable = true)\n",
      " |-- WorldRegion: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- LocationText: string (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- Decommisioned: boolean (nullable = true)\n",
      " |-- TaxReturnsFiled: string (nullable = true)\n",
      " |-- EstimatedPopulation: integer (nullable = true)\n",
      " |-- TotalWages: integer (nullable = true)\n",
      " |-- Notes: string (nullable = true)\n",
      "\n",
      "+------------+-------+-----------+-------------------+-----+--------------+-----+------+-----+-----+-----+-----------+-------+--------------------+--------------------+-------------+---------------+-------------------+----------+-----+\n",
      "|RecordNumber|Zipcode|ZipCodeType|               City|State|  LocationType|  Lat|  Long|Xaxis|Yaxis|Zaxis|WorldRegion|Country|        LocationText|            Location|Decommisioned|TaxReturnsFiled|EstimatedPopulation|TotalWages|Notes|\n",
      "+------------+-------+-----------+-------------------+-----+--------------+-----+------+-----+-----+-----+-----------+-------+--------------------+--------------------+-------------+---------------+-------------------+----------+-----+\n",
      "|           1|    704|   STANDARD|        PARC PARQUE|   PR|NOT ACCEPTABLE|17.96|-66.22| null|-0.87|  0.3|         NA|     US|     Parc Parque, PR|NA-US-PR-PARC PARQUE|        false|           null|               null|      null| null|\n",
      "|           2|    704|   STANDARD|PASEO COSTA DEL SUR|   PR|NOT ACCEPTABLE|17.96|-66.22| null|-0.87|  0.3|         NA|     US|Paseo Costa Del S...|NA-US-PR-PASEO CO...|        false|           null|               null|      null| null|\n",
      "|          10|    709|   STANDARD|       BDA SAN LUIS|   PR|NOT ACCEPTABLE|18.14|-66.26| null|-0.86| 0.31|         NA|     US|    Bda San Luis, PR|NA-US-PR-BDA SAN ...|        false|           null|               null|      null| null|\n",
      "|       61391|  76166|     UNIQUE|  CINGULAR WIRELESS|   TX|NOT ACCEPTABLE|32.72|-97.31| null|-0.83| 0.54|         NA|     US|Cingular Wireless...|NA-US-TX-CINGULAR...|        false|           null|               null|      null| null|\n",
      "|       61392|  76177|   STANDARD|         FORT WORTH|   TX|       PRIMARY|32.75|-97.33| null|-0.83| 0.54|         NA|     US|      Fort Worth, TX| NA-US-TX-FORT WORTH|        false|           2126|               4053| 122396986| null|\n",
      "+------------+-------+-----------+-------------------+-----+--------------+-----+------+-----+-----+-----+-----------+-------+--------------------+--------------------+-------------+---------------+-------------------+----------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_with_schema_json = spark.read.schema(schema) \\\n",
    "        .json(\"/Users/Storage/OtherTeaching/Data/zipcodes.json\")\n",
    "df_with_schema_json.printSchema()\n",
    "df_with_schema_json.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21bbdc13",
   "metadata": {},
   "source": [
    "### 3. Create DataFrame from RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f6ec45fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data into RDD\n",
    "def extract(line):\n",
    "    split_line = line.split(\",\")\n",
    "    result = [split_line[idx] for idx in [0,1,2,3,5,11]]\n",
    "    return result\n",
    "\n",
    "rdd = spark.sparkContext.textFile('/Users/Storage/OtherTeaching/Python/practice/epldata_final.csv') \\\n",
    "    .filter(lambda line: len(line.split()) > 1)\\\n",
    "    .map(extract)\n",
    "# rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c73c96c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------+---+--------+------------+--------------+\n",
      "|             name|   club|age|position|market_value|   nationality|\n",
      "+-----------------+-------+---+--------+------------+--------------+\n",
      "|   Alexis Sanchez|Arsenal| 28|      LW|          65|         Chile|\n",
      "|       Mesut Ozil|Arsenal| 28|      AM|          50|       Germany|\n",
      "|        Petr Cech|Arsenal| 35|      GK|           7|Czech Republic|\n",
      "|     Theo Walcott|Arsenal| 28|      RW|          20|       England|\n",
      "|Laurent Koscielny|Arsenal| 31|      CB|          22|        France|\n",
      "+-----------------+-------+---+--------+------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# convert RDD to DataFrame\n",
    "df_rdd = rdd.toDF([\"name\",\"club\",\"age\",\"position\",\"market_value\",\"nationality\"])\n",
    "df_rdd.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b8eeee54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- club: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- position: string (nullable = true)\n",
      " |-- market_value: double (nullable = true)\n",
      " |-- nationality: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_rdd = df_rdd.withColumn(\"age\",col(\"age\").cast(IntegerType())) \\\n",
    "    .withColumn(\"market_value\", col(\"market_value\").cast(DoubleType()))\n",
    "df_rdd.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb566fa1",
   "metadata": {},
   "source": [
    "### 4. DataFrame Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e2cbbee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------+---+--------+------------+--------------+\n",
      "|             name|   club|age|position|market_value|   nationality|\n",
      "+-----------------+-------+---+--------+------------+--------------+\n",
      "|   Alexis Sanchez|Arsenal| 28|      LW|          65|         Chile|\n",
      "|       Mesut Ozil|Arsenal| 28|      AM|          50|       Germany|\n",
      "|        Petr Cech|Arsenal| 35|      GK|           7|Czech Republic|\n",
      "|     Theo Walcott|Arsenal| 28|      RW|          20|       England|\n",
      "|Laurent Koscielny|Arsenal| 31|      CB|          22|        France|\n",
      "+-----------------+-------+---+--------+------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# select columns\n",
    "df2.select(\"name\",\"club\",\"age\",\"position\",\"market_value\",\"nationality\") \\\n",
    "    .show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8627ea4",
   "metadata": {},
   "source": [
    "#### Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b407c829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+-------+---+--------+------------+-----------+\n",
      "|name                 |club   |age|position|market_value|nationality|\n",
      "+---------------------+-------+---+--------+------------+-----------+\n",
      "|Eden Hazard          |Chelsea|26 |LW      |75.0        |Belgium    |\n",
      "|Diego Costa          |Chelsea|28 |CF      |50.0        |Spain      |\n",
      "|Gary Cahill          |Chelsea|31 |CB      |16.0        |England    |\n",
      "|Marcos Alonso Mendoza|Chelsea|26 |LB      |25.0        |Spain      |\n",
      "|Cesar Azpilicueta    |Chelsea|27 |RB      |30.0        |Spain      |\n",
      "+---------------------+-------+---+--------+------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# filter rows\n",
    "df_rdd.filter(df_rdd.club == 'Chelsea') \\\n",
    "        .select(\"name\",\"club\",\"age\",\"position\",\"market_value\",\"nationality\") \\\n",
    "        .show(5,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "47ee5576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------+---+--------+------------+-----------+\n",
      "|name            |club   |age|position|market_value|nationality|\n",
      "+----------------+-------+---+--------+------------+-----------+\n",
      "|Eduardo Carvalho|Chelsea|34 |LW      |0.05        |Portugal   |\n",
      "|Willy Caballero |Chelsea|35 |GK      |1.5         |Argentina  |\n",
      "|Kurt Zouma      |Chelsea|22 |CB      |15.0        |France     |\n",
      "|Tiemoue Bakayoko|Chelsea|22 |DM      |16.0        |France     |\n",
      "|Gary Cahill     |Chelsea|31 |CB      |16.0        |England    |\n",
      "+----------------+-------+---+--------+------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Filter then sort by column\n",
    "df_rdd.filter(df_rdd.club == 'Chelsea') \\\n",
    "        .select(\"name\",\"club\",\"age\",\"position\",\"market_value\",\"nationality\") \\\n",
    "        .orderBy('market_value') \\\n",
    "        .show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "777c0fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------+---+--------+------------+-----------+\n",
      "|name            |club   |age|position|market_value|nationality|\n",
      "+----------------+-------+---+--------+------------+-----------+\n",
      "|Eduardo Carvalho|Chelsea|34 |LW      |0.05        |Portugal   |\n",
      "|Oliver McBurnie |Swansea|21 |CF      |0.25        |Scotland   |\n",
      "|Jay Fulton      |Swansea|23 |CM      |0.5         |Scotland   |\n",
      "|Stephen Kingsley|Swansea|22 |LB      |0.75        |Scotland   |\n",
      "|Ã€ngel Rangel   |Swansea|34 |RB      |1.0         |Spain      |\n",
      "+----------------+-------+---+--------+------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# expr = col('club') == 'Chelsea'\n",
    "# expr = \"club == 'Chelsea'\" \n",
    "# expr = \"club <> 'Chelsea'\" \n",
    "# expr = col('club') != 'Chelsea'\n",
    "# expr = col('club').isin(['Chelsea'])\n",
    "# expr = col('club').startswith(\"Chel\")\n",
    "# expr = col('club').endswith(\"ea\")\n",
    "expr = col('club').like(\"%ea%\")\n",
    "df_rdd.filter(expr) \\\n",
    "        .select(\"name\",\"club\",\"age\",\"position\",\"market_value\",\"nationality\") \\\n",
    "        .orderBy('market_value') \\\n",
    "        .show(5, truncate=False)\n",
    "\n",
    "# NOTE: array_contains(col('club'),\"xxx\") if club column is an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "30af400b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[name: string, club: string, age: int, position: string, market_value: double, nationality: string]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter NULL\n",
    "# expr = \"club is NULL\"\n",
    "# expr = df_rdd.club.isNull()\n",
    "# expr = col(\"club\").isNull()\n",
    "# expr = \"club is not NULL\"\n",
    "# expr = \"NOT club is NULL\"\n",
    "expr = col(\"club\").isNotNull()\n",
    "\n",
    "df_rdd.filter(expr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703411a7",
   "metadata": {},
   "source": [
    "#### Create new column with concat function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "10c4f51d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------+---+--------+------------+--------------+-------+\n",
      "|             name|   club|age|position|market_value|   nationality|age_pos|\n",
      "+-----------------+-------+---+--------+------------+--------------+-------+\n",
      "|   Alexis Sanchez|Arsenal| 28|      LW|        65.0|         Chile|   28LW|\n",
      "|       Mesut Ozil|Arsenal| 28|      AM|        50.0|       Germany|   28AM|\n",
      "|        Petr Cech|Arsenal| 35|      GK|         7.0|Czech Republic|   35GK|\n",
      "|     Theo Walcott|Arsenal| 28|      RW|        20.0|       England|   28RW|\n",
      "|Laurent Koscielny|Arsenal| 31|      CB|        22.0|        France|   31CB|\n",
      "+-----------------+-------+---+--------+------------+--------------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# from pyspark.sql.functions import concat\n",
    "\n",
    "df_newcol = df_rdd.withColumn('age_pos',concat(col('age'), col('position')))\n",
    "df_newcol.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509d4917",
   "metadata": {},
   "source": [
    "#### Drop a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e68a87b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------+---+--------+------------+--------------+\n",
      "|             name|   club|age|position|market_value|   nationality|\n",
      "+-----------------+-------+---+--------+------------+--------------+\n",
      "|   Alexis Sanchez|Arsenal| 28|      LW|        65.0|         Chile|\n",
      "|       Mesut Ozil|Arsenal| 28|      AM|        50.0|       Germany|\n",
      "|        Petr Cech|Arsenal| 35|      GK|         7.0|Czech Republic|\n",
      "|     Theo Walcott|Arsenal| 28|      RW|        20.0|       England|\n",
      "|Laurent Koscielny|Arsenal| 31|      CB|        22.0|        France|\n",
      "+-----------------+-------+---+--------+------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_newcol.drop('age_pos').show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b6531b",
   "metadata": {},
   "source": [
    "#### Drop row with NULL value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cb49c00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.na.drop().show(truncate=False)\n",
    "# df.na.drop(how=\"any\").show(truncate=False)\n",
    "# df.na.drop(subset=[\"club\",\"nationality\"]).show(truncate=False)\n",
    "# df.dropna().show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0351b2",
   "metadata": {},
   "source": [
    "#### Drop duplicate rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "590cf7f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- employee_name: string (nullable = true)\n",
      " |-- department: string (nullable = true)\n",
      " |-- salary: long (nullable = true)\n",
      "\n",
      "+-------------+----------+------+\n",
      "|employee_name|department|salary|\n",
      "+-------------+----------+------+\n",
      "|James        |Sales     |3000  |\n",
      "|Michael      |Sales     |4600  |\n",
      "|Robert       |Sales     |4100  |\n",
      "|Maria        |Finance   |3000  |\n",
      "|James        |Sales     |3000  |\n",
      "|Scott        |Finance   |3300  |\n",
      "|Jen          |Finance   |3900  |\n",
      "|Jeff         |Marketing |3000  |\n",
      "|Kumar        |Marketing |2000  |\n",
      "|Saif         |Sales     |4100  |\n",
      "+-------------+----------+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct count: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 25:==============================================>        (84 + 2) / 100]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+------+\n",
      "|employee_name|department|salary|\n",
      "+-------------+----------+------+\n",
      "|Jen          |Finance   |3900  |\n",
      "|Michael      |Sales     |4600  |\n",
      "|Scott        |Finance   |3300  |\n",
      "|Kumar        |Marketing |2000  |\n",
      "|James        |Sales     |3000  |\n",
      "|Robert       |Sales     |4100  |\n",
      "|Jeff         |Marketing |3000  |\n",
      "|Saif         |Sales     |4100  |\n",
      "|Maria        |Finance   |3000  |\n",
      "+-------------+----------+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct count: 9\n",
      "+-------------+----------+------+\n",
      "|employee_name|department|salary|\n",
      "+-------------+----------+------+\n",
      "|Jen          |Finance   |3900  |\n",
      "|Michael      |Sales     |4600  |\n",
      "|Scott        |Finance   |3300  |\n",
      "|Kumar        |Marketing |2000  |\n",
      "|James        |Sales     |3000  |\n",
      "|Robert       |Sales     |4100  |\n",
      "|Jeff         |Marketing |3000  |\n",
      "|Saif         |Sales     |4100  |\n",
      "|Maria        |Finance   |3000  |\n",
      "+-------------+----------+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct count of department salary : 8\n",
      "+-------------+----------+------+\n",
      "|employee_name|department|salary|\n",
      "+-------------+----------+------+\n",
      "|Michael      |Sales     |4600  |\n",
      "|Robert       |Sales     |4100  |\n",
      "|Jen          |Finance   |3900  |\n",
      "|Maria        |Finance   |3000  |\n",
      "|Scott        |Finance   |3300  |\n",
      "|Kumar        |Marketing |2000  |\n",
      "|James        |Sales     |3000  |\n",
      "|Jeff         |Marketing |3000  |\n",
      "+-------------+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [(\"James\", \"Sales\", 3000), \\\n",
    "    (\"Michael\", \"Sales\", 4600), \\\n",
    "    (\"Robert\", \"Sales\", 4100), \\\n",
    "    (\"Maria\", \"Finance\", 3000), \\\n",
    "    (\"James\", \"Sales\", 3000), \\\n",
    "    (\"Scott\", \"Finance\", 3300), \\\n",
    "    (\"Jen\", \"Finance\", 3900), \\\n",
    "    (\"Jeff\", \"Marketing\", 3000), \\\n",
    "    (\"Kumar\", \"Marketing\", 2000), \\\n",
    "    (\"Saif\", \"Sales\", 4100) \\\n",
    "  ]\n",
    "columns= [\"employee_name\", \"department\", \"salary\"]\n",
    "xdf = spark.createDataFrame(data = data, schema = columns)\n",
    "xdf.printSchema()\n",
    "xdf.show(truncate=False)\n",
    "\n",
    "xdistinctDF = xdf.distinct()\n",
    "print(\"Distinct count: \"+str(xdistinctDF.count()))\n",
    "xdistinctDF.show(truncate=False)\n",
    "\n",
    "xdf2 = xdf.dropDuplicates()\n",
    "print(\"Distinct count: \"+str(xdf2.count()))\n",
    "xdf2.show(truncate=False)\n",
    "\n",
    "xdropDisDF = xdf.dropDuplicates([\"department\",\"salary\"])\n",
    "print(\"Distinct count of department salary : \"+str(xdropDisDF.count()))\n",
    "xdropDisDF.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3fed9c3",
   "metadata": {},
   "source": [
    "#### GROUP BY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0297e2d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 55:===================================>                  (131 + 1) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------------------+\n",
      "|             club|       total_value|\n",
      "+-----------------+------------------+\n",
      "|          Arsenal|             550.0|\n",
      "|  Manchester+City|             528.0|\n",
      "|Manchester+United| 514.1000000014901|\n",
      "|          Chelsea|486.55000000074506|\n",
      "|        Tottenham|             460.0|\n",
      "|        Liverpool|             440.5|\n",
      "|          Everton|            282.75|\n",
      "|      Southampton|             230.0|\n",
      "|   Leicester+City|             207.5|\n",
      "|         West+Ham|             186.0|\n",
      "|   Crystal+Palace|            162.25|\n",
      "|       Stoke+City|             150.0|\n",
      "|          Swansea|             139.0|\n",
      "|          Watford|             118.5|\n",
      "|      Bournemouth|             117.5|\n",
      "| Newcastle+United|            104.25|\n",
      "|        West+Brom|            101.25|\n",
      "|          Burnley|             71.25|\n",
      "|Brighton+and+Hove|              55.0|\n",
      "|     Huddersfield| 50.14999997615814|\n",
      "+-----------------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 55:=====================================================>(199 + 1) / 200]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# from pyspark.sql.functions import sum\n",
    "\n",
    "df_newcol.select('club',col('market_value').cast('float')).groupBy('club') \\\n",
    "    .agg(sum('market_value').alias('total_value')) \\\n",
    "    .orderBy(col('total_value').desc()) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3106dd4",
   "metadata": {},
   "source": [
    "#### expr function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "be789636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+-----------+\n",
      "| col1| col2|       Name|\n",
      "+-----+-----+-----------+\n",
      "|James| Bond| James,Bond|\n",
      "|Scott|Varsa|Scott,Varsa|\n",
      "+-----+-----+-----------+\n",
      "\n",
      "+-------+-------+\n",
      "|   name| gender|\n",
      "+-------+-------+\n",
      "|  James|   Male|\n",
      "|Michael| Female|\n",
      "|    Jen|unknown|\n",
      "+-------+-------+\n",
      "\n",
      "+----------+---------+----------+\n",
      "|      date|increment|  inc_date|\n",
      "+----------+---------+----------+\n",
      "|2023-01-23|        1|2023-02-23|\n",
      "|2023-06-24|        2|2023-08-24|\n",
      "|2023-09-20|        3|2023-12-20|\n",
      "+----------+---------+----------+\n",
      "\n",
      "+----------+---------+----------+\n",
      "|      date|increment|  inc_date|\n",
      "+----------+---------+----------+\n",
      "|2023-01-23|        1|2023-02-23|\n",
      "|2023-06-24|        2|2023-08-24|\n",
      "|2023-09-20|        3|2023-12-20|\n",
      "+----------+---------+----------+\n",
      "\n",
      "+----------+---------+-------------+\n",
      "|      date|increment|new_increment|\n",
      "+----------+---------+-------------+\n",
      "|2023-01-23|        1|            6|\n",
      "|2023-06-24|        2|            7|\n",
      "|2023-09-20|        3|            8|\n",
      "+----------+---------+-------------+\n",
      "\n",
      "root\n",
      " |-- increment: long (nullable = true)\n",
      " |-- str_increment: string (nullable = true)\n",
      "\n",
      "+----+----+\n",
      "|col1|col2|\n",
      "+----+----+\n",
      "| 500| 500|\n",
      "+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import expr\n",
    "\n",
    "#Concatenate columns\n",
    "data=[(\"James\",\"Bond\"),(\"Scott\",\"Varsa\")] \n",
    "df=spark.createDataFrame(data).toDF(\"col1\",\"col2\") \n",
    "df.withColumn(\"Name\",expr(\"col1 ||','|| col2\")).show()\n",
    "\n",
    "#Using CASE WHEN sql expression\n",
    "data = [(\"James\",\"M\"),(\"Michael\",\"F\"),(\"Jen\",\"\")]\n",
    "columns = [\"name\",\"gender\"]\n",
    "df = spark.createDataFrame(data = data, schema = columns)\n",
    "df2 = df.withColumn(\"gender\", expr(\"CASE WHEN gender = 'M' THEN 'Male' \" +\n",
    "           \"WHEN gender = 'F' THEN 'Female' ELSE 'unknown' END\"))\n",
    "df2.show()\n",
    "\n",
    "#Add months from a value of another column\n",
    "data=[(\"2023-01-23\",1),(\"2023-06-24\",2),(\"2023-09-20\",3)] \n",
    "df=spark.createDataFrame(data).toDF(\"date\",\"increment\") \n",
    "\n",
    "df.select(df.date,df.increment,\n",
    "     expr(\"add_months(date,increment)\")\n",
    "  .alias(\"inc_date\")).show()\n",
    "\n",
    "# Providing alias using 'as'\n",
    "df.select(df.date,df.increment,\n",
    "     expr(\"\"\"add_months(date,increment) as inc_date\"\"\")\n",
    "  ).show()\n",
    "\n",
    "# Add\n",
    "df.select(df.date,df.increment,\n",
    "     expr(\"increment + 5 as new_increment\")\n",
    "  ).show()\n",
    "\n",
    "df.select(\"increment\",expr(\"cast(increment as string) as str_increment\")).printSchema()\n",
    "\n",
    "#Use expr()  to filter the rows\n",
    "data=[(100,2),(200,3000),(500,500)] \n",
    "df=spark.createDataFrame(data).toDF(\"col1\",\"col2\") \n",
    "df.filter(expr(\"col1 == col2\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02755758",
   "metadata": {},
   "source": [
    "#### Sort function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "271ad485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+\n",
      "|col1|col2|\n",
      "+----+----+\n",
      "| 200|3000|\n",
      "| 500| 500|\n",
      "| 100|   2|\n",
      "+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.sort(col('col2').desc()).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b95cea",
   "metadata": {},
   "source": [
    "#### PIVOT TABLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bad03fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----+-----+-----+-----+-----+----+----+-----+-----+-----+----+-----+----+\n",
      "|club             |AM  |CB   |CF   |CM   |DM   |GK  |LB  |LM   |LW   |RB   |RM  |RW   |SS  |\n",
      "+-----------------+----+-----+-----+-----+-----+----+----+-----+-----+-----+----+-----+----+\n",
      "|Tottenham        |40.0|70.0 |73.0 |87.0 |50.0 |28.0|40.0|null |37.0 |10.0 |null|25.0 |null|\n",
      "|Brighton+and+Hove|null|12.25|9.0  |13.75|null |3.75|3.5 |null |3.25 |1.0  |0.5 |8.0  |null|\n",
      "|West+Ham         |15.0|28.0 |21.0 |21.0 |12.0 |2.5 |19.0|null |18.0 |11.5 |null|38.0 |null|\n",
      "|Leicester+City   |null|18.5 |70.0 |12.0 |38.0 |10.5|8.5 |6.0  |9.0  |5.0  |null|30.0 |null|\n",
      "|Arsenal          |50.0|78.0 |92.0 |65.0 |60.0 |15.0|38.0|null |75.0 |35.0 |22.0|20.0 |null|\n",
      "|Manchester+United|65.0|103.0|98.0 |117.0|4.0  |46.1|42.0|5.0  |12.0 |22.0 |null|null |null|\n",
      "|West+Brom        |null|9.0  |25.0 |5.25 |11.0 |5.5 |null|4.0  |20.5 |10.5 |null|10.5 |null|\n",
      "|Burnley          |null|8.5  |17.0 |13.0 |9.0  |4.0 |1.5 |13.25|null |2.5  |null|2.5  |null|\n",
      "|Bournemouth      |null|18.0 |29.0 |13.5 |null |10.0|5.0 |null |18.5 |7.5  |null|8.0  |8.0 |\n",
      "|Newcastle+United |5.5 |14.5 |21.5 |17.0 |5.0  |5.5 |5.0 |null |0.75 |7.5  |9.0 |5.0  |8.0 |\n",
      "|Southampton      |15.0|39.25|37.0 |29.0 |20.0 |15.0|23.0|0.75 |17.0 |15.0 |3.5 |15.5 |null|\n",
      "|Swansea          |25.0|17.0 |21.75|27.5 |7.0  |10.5|5.75|null |7.0  |6.0  |null|11.5 |null|\n",
      "|Huddersfield     |0.75|8.15 |14.5 |7.0  |null |1.75|2.25|null |2.5  |2.0  |null|11.25|null|\n",
      "|Crystal+Palace   |5.5 |13.0 |34.0 |27.0 |10.0 |4.25|23.0|null |6.0  |8.0  |null|31.5 |null|\n",
      "|Liverpool        |70.0|64.5 |42.0 |73.0 |22.0 |20.0|10.0|null |43.5 |22.5 |null|35.0 |38.0|\n",
      "|Chelsea          |null|86.0 |75.0 |35.0 |101.0|41.5|25.0|null |75.05|30.0 |18.0|null |null|\n",
      "|Manchester+City  |95.0|87.0 |110.0|46.0 |null |30.0|10.0|null |80.0 |30.0 |null|40.0 |null|\n",
      "|Watford          |15.0|15.0 |17.0 |22.0 |16.5 |4.0 |2.0 |null |8.5  |11.0 |null|5.5  |2.0 |\n",
      "|Everton          |43.0|45.5 |10.0 |41.0 |28.5 |22.0|12.0|null |25.0 |19.25|null|18.0 |18.5|\n",
      "|Stoke+City       |null|17.0 |26.5 |18.5 |14.5 |16.0|8.0 |3.0  |20.0 |6.5  |null|15.0 |5.0 |\n",
      "+-----------------+----+-----+-----+-----+-----+----+----+-----+-----+-----+----+-----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# from pyspark.sql.functions import round\n",
    "\n",
    "pivotDF = df_newcol.select('club',col('market_value').cast('float'), 'position') \\\n",
    "        .groupBy(\"club\").pivot(\"position\").agg(round(sum(\"market_value\"),2))\n",
    "# pivotDF.printSchema()\n",
    "pivotDF.show(truncate=False)\n",
    "\n",
    "# pivotDF = df_newcol.select('club',col('market_value').cast('float'), 'position') \\\n",
    "#         .groupBy(\"club\",\"position\") \\\n",
    "#       .sum(\"market_value\") \\\n",
    "#       .groupBy(\"club\") \\\n",
    "#       .pivot(\"position\") \\\n",
    "#       .sum(\"sum(market_value)\")\n",
    "# pivotDF.printSchema()\n",
    "# pivotDF.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6113f9",
   "metadata": {},
   "source": [
    "#### JOIN DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6beeb540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+---------------+-----------+-----------+------+------+\n",
      "|emp_id|name    |superior_emp_id|year_joined|emp_dept_id|gender|salary|\n",
      "+------+--------+---------------+-----------+-----------+------+------+\n",
      "|1     |Smith   |-1             |2018       |10         |M     |3000  |\n",
      "|2     |Rose    |1              |2010       |20         |M     |4000  |\n",
      "|3     |Williams|1              |2010       |10         |M     |1000  |\n",
      "|4     |Jones   |2              |2005       |10         |F     |2000  |\n",
      "|5     |Brown   |2              |2010       |40         |      |-1    |\n",
      "|6     |Brown   |2              |2010       |50         |      |-1    |\n",
      "+------+--------+---------------+-----------+-----------+------+------+\n",
      "\n",
      "+---------+-------+\n",
      "|dept_name|dept_id|\n",
      "+---------+-------+\n",
      "|Finance  |10     |\n",
      "|Marketing|20     |\n",
      "|Sales    |30     |\n",
      "|IT       |40     |\n",
      "+---------+-------+\n",
      "\n",
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "|emp_id|name    |superior_emp_id|year_joined|emp_dept_id|gender|salary|dept_name|dept_id|\n",
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "|1     |Smith   |-1             |2018       |10         |M     |3000  |Finance  |10     |\n",
      "|3     |Williams|1              |2010       |10         |M     |1000  |Finance  |10     |\n",
      "|4     |Jones   |2              |2005       |10         |F     |2000  |Finance  |10     |\n",
      "|2     |Rose    |1              |2010       |20         |M     |4000  |Marketing|20     |\n",
      "|5     |Brown   |2              |2010       |40         |      |-1    |IT       |40     |\n",
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "\n",
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "|emp_id|name    |superior_emp_id|year_joined|emp_dept_id|gender|salary|dept_name|dept_id|\n",
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "|6     |Brown   |2              |2010       |50         |      |-1    |null     |null   |\n",
      "|1     |Smith   |-1             |2018       |10         |M     |3000  |Finance  |10     |\n",
      "|3     |Williams|1              |2010       |10         |M     |1000  |Finance  |10     |\n",
      "|4     |Jones   |2              |2005       |10         |F     |2000  |Finance  |10     |\n",
      "|null  |null    |null           |null       |null       |null  |null  |Sales    |30     |\n",
      "|2     |Rose    |1              |2010       |20         |M     |4000  |Marketing|20     |\n",
      "|5     |Brown   |2              |2010       |40         |      |-1    |IT       |40     |\n",
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "\n",
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "|emp_id|name    |superior_emp_id|year_joined|emp_dept_id|gender|salary|dept_name|dept_id|\n",
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "|6     |Brown   |2              |2010       |50         |      |-1    |null     |null   |\n",
      "|1     |Smith   |-1             |2018       |10         |M     |3000  |Finance  |10     |\n",
      "|3     |Williams|1              |2010       |10         |M     |1000  |Finance  |10     |\n",
      "|4     |Jones   |2              |2005       |10         |F     |2000  |Finance  |10     |\n",
      "|null  |null    |null           |null       |null       |null  |null  |Sales    |30     |\n",
      "|2     |Rose    |1              |2010       |20         |M     |4000  |Marketing|20     |\n",
      "|5     |Brown   |2              |2010       |40         |      |-1    |IT       |40     |\n",
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "\n",
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "|emp_id|name    |superior_emp_id|year_joined|emp_dept_id|gender|salary|dept_name|dept_id|\n",
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "|6     |Brown   |2              |2010       |50         |      |-1    |null     |null   |\n",
      "|1     |Smith   |-1             |2018       |10         |M     |3000  |Finance  |10     |\n",
      "|3     |Williams|1              |2010       |10         |M     |1000  |Finance  |10     |\n",
      "|4     |Jones   |2              |2005       |10         |F     |2000  |Finance  |10     |\n",
      "|null  |null    |null           |null       |null       |null  |null  |Sales    |30     |\n",
      "|2     |Rose    |1              |2010       |20         |M     |4000  |Marketing|20     |\n",
      "|5     |Brown   |2              |2010       |40         |      |-1    |IT       |40     |\n",
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 154:===================================================>  (95 + 1) / 100]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "|emp_id|name    |superior_emp_id|year_joined|emp_dept_id|gender|salary|dept_name|dept_id|\n",
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "|6     |Brown   |2              |2010       |50         |      |-1    |null     |null   |\n",
      "|1     |Smith   |-1             |2018       |10         |M     |3000  |Finance  |10     |\n",
      "|3     |Williams|1              |2010       |10         |M     |1000  |Finance  |10     |\n",
      "|4     |Jones   |2              |2005       |10         |F     |2000  |Finance  |10     |\n",
      "|2     |Rose    |1              |2010       |20         |M     |4000  |Marketing|20     |\n",
      "|5     |Brown   |2              |2010       |40         |      |-1    |IT       |40     |\n",
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "\n",
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "|emp_id|name    |superior_emp_id|year_joined|emp_dept_id|gender|salary|dept_name|dept_id|\n",
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "|6     |Brown   |2              |2010       |50         |      |-1    |null     |null   |\n",
      "|1     |Smith   |-1             |2018       |10         |M     |3000  |Finance  |10     |\n",
      "|3     |Williams|1              |2010       |10         |M     |1000  |Finance  |10     |\n",
      "|4     |Jones   |2              |2005       |10         |F     |2000  |Finance  |10     |\n",
      "|2     |Rose    |1              |2010       |20         |M     |4000  |Marketing|20     |\n",
      "|5     |Brown   |2              |2010       |40         |      |-1    |IT       |40     |\n",
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 184:====================================================> (97 + 1) / 100]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "|emp_id|name    |superior_emp_id|year_joined|emp_dept_id|gender|salary|dept_name|dept_id|\n",
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "|1     |Smith   |-1             |2018       |10         |M     |3000  |Finance  |10     |\n",
      "|3     |Williams|1              |2010       |10         |M     |1000  |Finance  |10     |\n",
      "|4     |Jones   |2              |2005       |10         |F     |2000  |Finance  |10     |\n",
      "|null  |null    |null           |null       |null       |null  |null  |Sales    |30     |\n",
      "|2     |Rose    |1              |2010       |20         |M     |4000  |Marketing|20     |\n",
      "|5     |Brown   |2              |2010       |40         |      |-1    |IT       |40     |\n",
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "\n",
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "|emp_id|name    |superior_emp_id|year_joined|emp_dept_id|gender|salary|dept_name|dept_id|\n",
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "|1     |Smith   |-1             |2018       |10         |M     |3000  |Finance  |10     |\n",
      "|3     |Williams|1              |2010       |10         |M     |1000  |Finance  |10     |\n",
      "|4     |Jones   |2              |2005       |10         |F     |2000  |Finance  |10     |\n",
      "|null  |null    |null           |null       |null       |null  |null  |Sales    |30     |\n",
      "|2     |Rose    |1              |2010       |20         |M     |4000  |Marketing|20     |\n",
      "|5     |Brown   |2              |2010       |40         |      |-1    |IT       |40     |\n",
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "\n",
      "+------+--------+---------------+-----------+-----------+------+------+\n",
      "|emp_id|name    |superior_emp_id|year_joined|emp_dept_id|gender|salary|\n",
      "+------+--------+---------------+-----------+-----------+------+------+\n",
      "|1     |Smith   |-1             |2018       |10         |M     |3000  |\n",
      "|3     |Williams|1              |2010       |10         |M     |1000  |\n",
      "|4     |Jones   |2              |2005       |10         |F     |2000  |\n",
      "|2     |Rose    |1              |2010       |20         |M     |4000  |\n",
      "|5     |Brown   |2              |2010       |40         |      |-1    |\n",
      "+------+--------+---------------+-----------+-----------+------+------+\n",
      "\n",
      "+------+-----+---------------+-----------+-----------+------+------+\n",
      "|emp_id|name |superior_emp_id|year_joined|emp_dept_id|gender|salary|\n",
      "+------+-----+---------------+-----------+-----------+------+------+\n",
      "|6     |Brown|2              |2010       |50         |      |-1    |\n",
      "+------+-----+---------------+-----------+-----------+------+------+\n",
      "\n",
      "+------+--------+---------------+-----------------+\n",
      "|emp_id|name    |superior_emp_id|superior_emp_name|\n",
      "+------+--------+---------------+-----------------+\n",
      "|2     |Rose    |1              |Smith            |\n",
      "|3     |Williams|1              |Smith            |\n",
      "|4     |Jones   |2              |Rose             |\n",
      "|5     |Brown   |2              |Rose             |\n",
      "|6     |Brown   |2              |Rose             |\n",
      "+------+--------+---------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp = [(1,\"Smith\",-1,\"2018\",\"10\",\"M\",3000), \\\n",
    "    (2,\"Rose\",1,\"2010\",\"20\",\"M\",4000), \\\n",
    "    (3,\"Williams\",1,\"2010\",\"10\",\"M\",1000), \\\n",
    "    (4,\"Jones\",2,\"2005\",\"10\",\"F\",2000), \\\n",
    "    (5,\"Brown\",2,\"2010\",\"40\",\"\",-1), \\\n",
    "      (6,\"Brown\",2,\"2010\",\"50\",\"\",-1) \\\n",
    "  ]\n",
    "empColumns = [\"emp_id\",\"name\",\"superior_emp_id\",\"year_joined\", \\\n",
    "       \"emp_dept_id\",\"gender\",\"salary\"]\n",
    "\n",
    "empDF = spark.createDataFrame(data=emp, schema = empColumns)\n",
    "empDF.show(truncate=False)\n",
    "\n",
    "\n",
    "dept = [(\"Finance\",10), \\\n",
    "    (\"Marketing\",20), \\\n",
    "    (\"Sales\",30), \\\n",
    "    (\"IT\",40) \\\n",
    "  ]\n",
    "deptColumns = [\"dept_name\",\"dept_id\"]\n",
    "deptDF = spark.createDataFrame(data=dept, schema = deptColumns)\n",
    "deptDF.show(truncate=False)\n",
    "  \n",
    "empDF.join(deptDF,empDF.emp_dept_id ==  deptDF.dept_id,\"inner\") \\\n",
    "     .show(truncate=False)\n",
    "\n",
    "empDF.join(deptDF,empDF.emp_dept_id ==  deptDF.dept_id,\"outer\") \\\n",
    "    .show(truncate=False)\n",
    "empDF.join(deptDF,empDF.emp_dept_id ==  deptDF.dept_id,\"full\") \\\n",
    "    .show(truncate=False)\n",
    "empDF.join(deptDF,empDF.emp_dept_id ==  deptDF.dept_id,\"fullouter\") \\\n",
    "    .show(truncate=False)\n",
    "    \n",
    "empDF.join(deptDF,empDF.emp_dept_id ==  deptDF.dept_id,\"left\") \\\n",
    "    .show(truncate=False)\n",
    "empDF.join(deptDF,empDF.emp_dept_id ==  deptDF.dept_id,\"leftouter\") \\\n",
    "   .show(truncate=False)\n",
    "\n",
    "empDF.join(deptDF,empDF.emp_dept_id ==  deptDF.dept_id,\"right\") \\\n",
    "   .show(truncate=False)\n",
    "empDF.join(deptDF,empDF.emp_dept_id ==  deptDF.dept_id,\"rightouter\") \\\n",
    "   .show(truncate=False)\n",
    "\n",
    "empDF.join(deptDF,empDF.emp_dept_id ==  deptDF.dept_id,\"leftsemi\") \\\n",
    "   .show(truncate=False)\n",
    "   \n",
    "empDF.join(deptDF,empDF.emp_dept_id ==  deptDF.dept_id,\"leftanti\") \\\n",
    "   .show(truncate=False)\n",
    "   \n",
    "empDF.alias(\"emp1\").join(empDF.alias(\"emp2\"), \\\n",
    "    col(\"emp1.superior_emp_id\") == col(\"emp2.emp_id\"),\"inner\") \\\n",
    "    .select(col(\"emp1.emp_id\"),col(\"emp1.name\"), \\\n",
    "      col(\"emp2.emp_id\").alias(\"superior_emp_id\"), \\\n",
    "      col(\"emp2.name\").alias(\"superior_emp_name\")) \\\n",
    "   .show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535ff73e",
   "metadata": {},
   "source": [
    "#### Union 2 DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a678e9a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------------------+\n",
      "|             club|       total_value|\n",
      "+-----------------+------------------+\n",
      "|          Arsenal|             550.0|\n",
      "|  Manchester+City|             528.0|\n",
      "|Manchester+United| 514.1000000014901|\n",
      "|          Chelsea|486.55000000074506|\n",
      "|        Tottenham|             460.0|\n",
      "|        Liverpool|             440.5|\n",
      "+-----------------+------------------+\n",
      "\n",
      "+-----------------+-----------------+\n",
      "|             club|      total_value|\n",
      "+-----------------+-----------------+\n",
      "|          Everton|           282.75|\n",
      "|      Southampton|            230.0|\n",
      "|   Leicester+City|            207.5|\n",
      "|         West+Ham|            186.0|\n",
      "|   Crystal+Palace|           162.25|\n",
      "|       Stoke+City|            150.0|\n",
      "|          Swansea|            139.0|\n",
      "|          Watford|            118.5|\n",
      "|      Bournemouth|            117.5|\n",
      "| Newcastle+United|           104.25|\n",
      "|        West+Brom|           101.25|\n",
      "|          Burnley|            71.25|\n",
      "|Brighton+and+Hove|             55.0|\n",
      "|     Huddersfield|50.14999997615814|\n",
      "+-----------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_total = df_newcol.select('club',col('market_value').cast('float')).groupBy('club') \\\n",
    "    .agg(sum('market_value').alias('total_value')) \\\n",
    "    .orderBy(col('total_value').desc())\n",
    "\n",
    "df_big6 = df_total.filter(\"total_value > 300\")\n",
    "df_big6.show()\n",
    "\n",
    "df_big_rest = df_total.filter(\"total_value <= 300\")\n",
    "df_big_rest.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "62fa2fcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 258:===================================>                 (135 + 1) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------------------+\n",
      "|             club|       total_value|\n",
      "+-----------------+------------------+\n",
      "|          Arsenal|             550.0|\n",
      "|  Manchester+City|             528.0|\n",
      "|Manchester+United| 514.1000000014901|\n",
      "|          Chelsea|486.55000000074506|\n",
      "|        Tottenham|             460.0|\n",
      "|        Liverpool|             440.5|\n",
      "|          Everton|            282.75|\n",
      "|      Southampton|             230.0|\n",
      "|   Leicester+City|             207.5|\n",
      "|         West+Ham|             186.0|\n",
      "|   Crystal+Palace|            162.25|\n",
      "|       Stoke+City|             150.0|\n",
      "|          Swansea|             139.0|\n",
      "|          Watford|             118.5|\n",
      "|      Bournemouth|             117.5|\n",
      "| Newcastle+United|            104.25|\n",
      "|        West+Brom|            101.25|\n",
      "|          Burnley|             71.25|\n",
      "|Brighton+and+Hove|              55.0|\n",
      "|     Huddersfield| 50.14999997615814|\n",
      "+-----------------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 258:===================================================> (193 + 1) / 200]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_big6.union(df_big_rest).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51cf156b",
   "metadata": {},
   "source": [
    "#### WHEN function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a25d8fdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+\n",
      "|   name| gender|\n",
      "+-------+-------+\n",
      "|  James|   Male|\n",
      "|Michael| Female|\n",
      "|    Jen|unknown|\n",
      "+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# from pyspark.sql.functions import when\n",
    "\n",
    "data = [(\"James\",\"M\"),(\"Michael\",\"F\"),(\"Jen\",\"\")]\n",
    "df = spark.createDataFrame(data = data, schema = [\"name\",\"gender\"])\n",
    "df2 = df.withColumn(\"gender\", when(col('gender') == 'M','Male')\n",
    "                              .when(col('gender') == 'F','Female') \n",
    "                            .otherwise('unknown'))\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad694c5",
   "metadata": {},
   "source": [
    "#### Statistic functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "33b14db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyspark.sql.functions import collect_set,sum,avg,max,countDistinct,count,collect_list\n",
    "# from pyspark.sql.functions import first, last, kurtosis, min, mean, skewness \n",
    "# from pyspark.sql.functions import variance, stddev, stddev_samp, stddev_pop, sumDistinct, var_samp, var_pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3a539fa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|collect_list(total_value)                                                                                                                                                           |\n",
      "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|[550.0, 528.0, 514.1000000014901, 486.55000000074506, 460.0, 440.5, 282.75, 230.0, 207.5, 186.0, 162.25, 150.0, 139.0, 118.5, 117.5, 104.25, 101.25, 71.25, 55.0, 50.14999997615814]|\n",
      "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 278:================================================>    (182 + 1) / 200]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|collect_set(total_value)                                                                                                                                                            |\n",
      "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|[230.0, 207.5, 440.5, 71.25, 139.0, 55.0, 550.0, 282.75, 186.0, 50.14999997615814, 514.1000000014901, 486.55000000074506, 117.5, 528.0, 104.25, 150.0, 118.5, 101.25, 162.25, 460.0]|\n",
      "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------+\n",
      "|count(DISTINCT club, total_value)|\n",
      "+---------------------------------+\n",
      "|20                               |\n",
      "+---------------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|first(total_value)|\n",
      "+------------------+\n",
      "|550.0             |\n",
      "+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|last(total_value)|\n",
      "+-----------------+\n",
      "|50.14999997615814|\n",
      "+-----------------+\n",
      "\n",
      "+---------------------+\n",
      "|kurtosis(total_value)|\n",
      "+---------------------+\n",
      "|-1.2237757194547998  |\n",
      "+---------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 303:=========================================>           (158 + 1) / 200]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|max(total_value)|\n",
      "+----------------+\n",
      "|550.0           |\n",
      "+----------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 306:=====================================>               (143 + 1) / 200]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|min(total_value) |\n",
      "+-----------------+\n",
      "|50.14999997615814|\n",
      "+-----------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|avg(total_value)  |\n",
      "+------------------+\n",
      "|247.72749999891965|\n",
      "+------------------+\n",
      "\n",
      "+---------------------+\n",
      "|skewness(total_value)|\n",
      "+---------------------+\n",
      "|0.6268312950071274   |\n",
      "+---------------------+\n",
      "\n",
      "+------------------------+------------------------+-----------------------+\n",
      "|stddev_samp(total_value)|stddev_samp(total_value)|stddev_pop(total_value)|\n",
      "+------------------------+------------------------+-----------------------+\n",
      "|177.52779802871657      |177.52779802871657      |173.03269378726827     |\n",
      "+------------------------+------------------------+-----------------------+\n",
      "\n",
      "+-----------------+\n",
      "|sum(total_value) |\n",
      "+-----------------+\n",
      "|4954.549999978393|\n",
      "+-----------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 337:==========================================>          (159 + 1) / 200]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+\n",
      "|sum(DISTINCT total_value)|\n",
      "+-------------------------+\n",
      "|4954.549999978393        |\n",
      "+-------------------------+\n",
      "\n",
      "+---------------------+---------------------+--------------------+\n",
      "|var_samp(total_value)|var_samp(total_value)|var_pop(total_value)|\n",
      "+---------------------+---------------------+--------------------+\n",
      "|31516.119072924786   |31516.119072924786   |29940.313119278544  |\n",
      "+---------------------+---------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_total.select(collect_list(\"total_value\")).show(truncate=False)\n",
    "df_total.select(collect_set(\"total_value\")).show(truncate=False)\n",
    "df_total.select(countDistinct(\"club\", \"total_value\")).show(truncate=False)\n",
    "df_total.select(first(\"total_value\")).show(truncate=False)\n",
    "df_total.select(last(\"total_value\")).show(truncate=False)\n",
    "df_total.select(kurtosis(\"total_value\")).show(truncate=False)\n",
    "df_total.select(max(\"total_value\")).show(truncate=False)\n",
    "df_total.select(min(\"total_value\")).show(truncate=False)\n",
    "df_total.select(mean(\"total_value\")).show(truncate=False)\n",
    "df_total.select(skewness(\"total_value\")).show(truncate=False)\n",
    "df_total.select(stddev(\"total_value\"), stddev_samp(\"total_value\"),stddev_pop(\"total_value\")).show(truncate=False)\n",
    "df_total.select(sum(\"total_value\")).show(truncate=False)\n",
    "df_total.select(sumDistinct(\"total_value\")).show(truncate=False)\n",
    "df_total.select(variance(\"total_value\"),var_samp(\"total_value\"),var_pop(\"total_value\")).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61dfd8a9",
   "metadata": {},
   "source": [
    "#### CREATE VIEW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "65d8e0c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------+---+--------+------------+--------------+\n",
      "|             name|   club|age|position|market_value|   nationality|\n",
      "+-----------------+-------+---+--------+------------+--------------+\n",
      "|   Alexis Sanchez|Arsenal| 28|      LW|        65.0|         Chile|\n",
      "|       Mesut Ozil|Arsenal| 28|      AM|        50.0|       Germany|\n",
      "|        Petr Cech|Arsenal| 35|      GK|         7.0|Czech Republic|\n",
      "|     Theo Walcott|Arsenal| 28|      RW|        20.0|       England|\n",
      "|Laurent Koscielny|Arsenal| 31|      CB|        22.0|        France|\n",
      "+-----------------+-------+---+--------+------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_rdd.createOrReplaceTempView(\"epldata\")\n",
    "spark.sql(\"SELECT * from epldata\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a32b8800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------------------+------------------+\n",
      "|             club|           avg_age|   avg_marketvalue|\n",
      "+-----------------+------------------+------------------+\n",
      "|        Tottenham|             25.65|              23.0|\n",
      "|Brighton+and+Hove|27.952380952380953| 2.619047619047619|\n",
      "|         West+Ham|27.238095238095237| 8.857142857142858|\n",
      "|   Leicester+City|             27.25| 8.645833333333334|\n",
      "|          Arsenal|26.678571428571427|19.642857142857142|\n",
      "|Manchester+United|             25.56|            20.564|\n",
      "|        West+Brom|28.210526315789473| 5.328947368421052|\n",
      "|          Burnley|27.944444444444443|3.9583333333333335|\n",
      "|      Bournemouth|            26.875| 4.895833333333333|\n",
      "| Newcastle+United|              26.4|            5.2125|\n",
      "|      Southampton|24.956521739130434|              10.0|\n",
      "|          Swansea|              27.0|              5.56|\n",
      "|     Huddersfield|              26.0|1.7910714285714284|\n",
      "|   Crystal+Palace|28.047619047619047| 7.726190476190476|\n",
      "|        Liverpool| 24.77777777777778|16.314814814814813|\n",
      "|          Chelsea|27.235294117647058|28.620588235294118|\n",
      "|  Manchester+City|26.444444444444443|29.333333333333332|\n",
      "|          Watford|28.130434782608695|5.1521739130434785|\n",
      "|          Everton|26.214285714285715|10.098214285714286|\n",
      "|       Stoke+City|28.045454545454547| 6.818181818181818|\n",
      "+-----------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT club, AVG(age) AS avg_age, AVG(market_value) AS avg_marketvalue FROM epldata GROUP BY club\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6ff40c",
   "metadata": {},
   "source": [
    "#### DateTime function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a44a8937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+--------+\n",
      "|      date|current_date|datediff|\n",
      "+----------+------------+--------+\n",
      "|2019-07-01|  2023-04-13|    1382|\n",
      "|2019-06-24|  2023-04-13|    1389|\n",
      "|2019-08-24|  2023-04-13|    1328|\n",
      "+----------+------------+--------+\n",
      "\n",
      "+---+----------+---------+-----------+----------------+------------------+---------------+\n",
      "| id|      date|datesDiff| monthsDiff|monthsDiff_round|         yearsDiff|yearsDiff_round|\n",
      "+---+----------+---------+-----------+----------------+------------------+---------------+\n",
      "|  1|2019-07-01|     1382|45.38709677|           45.39|3.7822580641666668|           3.78|\n",
      "|  2|2019-06-24|     1389|45.64516129|           45.65| 3.803763440833333|            3.8|\n",
      "|  3|2019-08-24|     1328|43.64516129|           43.65|3.6370967741666664|           3.64|\n",
      "+---+----------+---------+-----------+----------------+------------------+---------------+\n",
      "\n",
      "+----------+\n",
      "|years_diff|\n",
      "+----------+\n",
      "|      3.78|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [(\"1\",\"2019-07-01\"),(\"2\",\"2019-06-24\"),(\"3\",\"2019-08-24\")]\n",
    "\n",
    "df=spark.createDataFrame(data=data,schema=[\"id\",\"date\"])\n",
    "\n",
    "df.select(\n",
    "      col(\"date\"),\n",
    "      current_date().alias(\"current_date\"),\n",
    "      datediff(current_date(),col(\"date\")).alias(\"datediff\")\n",
    "    ).show()\n",
    "\n",
    "df.withColumn(\"datesDiff\", datediff(current_date(),col(\"date\"))) \\\n",
    "  .withColumn(\"monthsDiff\", months_between(current_date(),col(\"date\"))) \\\n",
    "  .withColumn(\"monthsDiff_round\",round(months_between(current_date(),col(\"date\")),2)) \\\n",
    "  .withColumn(\"yearsDiff\",months_between(current_date(),col(\"date\"))/lit(12)) \\\n",
    "  .withColumn(\"yearsDiff_round\",round(months_between(current_date(),col(\"date\"))/lit(12),2)) \\\n",
    "  .show()\n",
    "\n",
    "data2 = [(\"1\",\"07-01-2019\"),(\"2\",\"06-24-2019\"),(\"3\",\"08-24-2019\")]  \n",
    "df2=spark.createDataFrame(data=data2,schema=[\"id\",\"date\"])\n",
    "df2.select(\n",
    "    to_date(col(\"date\"),\"MM-dd-yyyy\").alias(\"date\"),\n",
    "    current_date().alias(\"endDate\")\n",
    "    )\n",
    "\n",
    "#SQL\n",
    "\n",
    "spark.sql(\"select round(months_between(current_date(), '2019-07-01')/12,2) as years_diff\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f623b193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------------------+\n",
      "|id |input                  |\n",
      "+---+-----------------------+\n",
      "|1  |02-01-2020 11 01 19 06 |\n",
      "|2  |03-01-2019 12 01 19 406|\n",
      "|3  |03-01-2021 12 01 19 406|\n",
      "+---+-----------------------+\n",
      "\n",
      "+-----------------------+\n",
      "|current_timestamp      |\n",
      "+-----------------------+\n",
      "|2023-04-13 22:38:25.702|\n",
      "+-----------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "+-----------------------+-----------------------+\n",
      "|input                  |to_timestamp           |\n",
      "+-----------------------+-----------------------+\n",
      "|02-01-2020 11 01 19 06 |2020-02-01 11:01:19.06 |\n",
      "|03-01-2019 12 01 19 406|2019-03-01 12:01:19.406|\n",
      "|03-01-2021 12 01 19 406|2021-03-01 12:01:19.406|\n",
      "+-----------------------+-----------------------+\n",
      "\n",
      "+-----------------------+----+------+------+\n",
      "|input                  |hour|minute|second|\n",
      "+-----------------------+----+------+------+\n",
      "|2020-02-01 11:01:19.06 |11  |1     |19    |\n",
      "|2019-03-01 12:01:19.406|12  |1     |19    |\n",
      "|2021-03-01 12:01:19.406|12  |1     |19    |\n",
      "+-----------------------+----+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data=[[\"1\",\"02-01-2020 11 01 19 06\"],[\"2\",\"03-01-2019 12 01 19 406\"],[\"3\",\"03-01-2021 12 01 19 406\"]]\n",
    "df2=spark.createDataFrame(data,[\"id\",\"input\"])\n",
    "df2.show(truncate=False)\n",
    "\n",
    "#current_timestamp()\n",
    "df2.select(current_timestamp().alias(\"current_timestamp\")).show(1,truncate=False)\n",
    "\n",
    "#to_timestamp()\n",
    "df2.select(col(\"input\"), \n",
    "    to_timestamp(col(\"input\"), \"MM-dd-yyyy HH mm ss SSS\").alias(\"to_timestamp\") \n",
    "  ).show(truncate=False)\n",
    "\n",
    "\n",
    "#hour, minute,second\n",
    "data=[[\"1\",\"2020-02-01 11:01:19.06\"],[\"2\",\"2019-03-01 12:01:19.406\"],[\"3\",\"2021-03-01 12:01:19.406\"]]\n",
    "df3=spark.createDataFrame(data,[\"id\",\"input\"])\n",
    "\n",
    "df3.select(col(\"input\"), \n",
    "    hour(col(\"input\")).alias(\"hour\"), \n",
    "    minute(col(\"input\")).alias(\"minute\"),\n",
    "    second(col(\"input\")).alias(\"second\") \n",
    "  ).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705df850",
   "metadata": {},
   "source": [
    "### 5. READ FROM MYSQL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fdf7527",
   "metadata": {},
   "source": [
    "##### read table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9493020f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- customerNumber: integer (nullable = true)\n",
      " |-- customerName: string (nullable = true)\n",
      " |-- contactLastName: string (nullable = true)\n",
      " |-- contactFirstName: string (nullable = true)\n",
      " |-- phone: string (nullable = true)\n",
      " |-- addressLine1: string (nullable = true)\n",
      " |-- addressLine2: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- postalCode: string (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      " |-- salesRepEmployeeNumber: integer (nullable = true)\n",
      " |-- creditLimit: decimal(10,2) (nullable = true)\n",
      "\n",
      "+--------------+--------------------+---------------+----------------+------------+--------------------+------------+---------+--------+----------+---------+----------------------+-----------+\n",
      "|customerNumber|        customerName|contactLastName|contactFirstName|       phone|        addressLine1|addressLine2|     city|   state|postalCode|  country|salesRepEmployeeNumber|creditLimit|\n",
      "+--------------+--------------------+---------------+----------------+------------+--------------------+------------+---------+--------+----------+---------+----------------------+-----------+\n",
      "|           103|   Atelier graphique|        Schmitt|         Carine |  40.32.2555|      54, rue Royale|        null|   Nantes|    null|     44000|   France|                  1370|   21000.00|\n",
      "|           112|  Signal Gift Stores|           King|            Jean|  7025551838|     8489 Strong St.|        null|Las Vegas|      NV|     83030|      USA|                  1166|   71800.00|\n",
      "|           114|Australian Collec...|       Ferguson|           Peter|03 9520 4555|   636 St Kilda Road|     Level 3|Melbourne|Victoria|      3004|Australia|                  1611|  117300.00|\n",
      "|           119|   La Rochelle Gifts|        Labrune|         Janine |  40.67.8555|67, rue des Cinqu...|        null|   Nantes|    null|     44000|   France|                  1370|  118200.00|\n",
      "|           121|  Baane Mini Imports|     Bergulfsen|          Jonas |  07-98 9555|Erling Skakkes ga...|        null|  Stavern|    null|      4110|   Norway|                  1504|   81700.00|\n",
      "+--------------+--------------------+---------------+----------------+------------+--------------------+------------+---------+--------+----------+---------+----------------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SQLContext\n",
    "\n",
    "sqlContext = SQLContext(spark.sparkContext)\n",
    "\n",
    "df = sqlContext \\\n",
    "      .read \\\n",
    "      .format(\"jdbc\") \\\n",
    "      .option(\"url\", \"jdbc:mysql://localhost:3306/classicmodels\") \\\n",
    "      .option(\"driver\", \"com.mysql.cj.jdbc.Driver\") \\\n",
    "    .option(\"user\",\"root\") \\\n",
    "    .option(\"password\", \"QA2015!@#\") \\\n",
    "      .option(\"dbtable\", \"customers\") \\\n",
    "      .load()\n",
    "\n",
    "# Looks the schema of this DataFrame.\n",
    "df.printSchema()\n",
    "\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c86a97",
   "metadata": {},
   "source": [
    "##### query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "69706597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- customerNumber: integer (nullable = true)\n",
      " |-- customerName: string (nullable = true)\n",
      " |-- salesRepEmployeeNumber: integer (nullable = true)\n",
      "\n",
      "+--------------+--------------------+----------------------+\n",
      "|customerNumber|        customerName|salesRepEmployeeNumber|\n",
      "+--------------+--------------------+----------------------+\n",
      "|           103|   Atelier graphique|                  1370|\n",
      "|           112|  Signal Gift Stores|                  1166|\n",
      "|           114|Australian Collec...|                  1611|\n",
      "|           119|   La Rochelle Gifts|                  1370|\n",
      "|           121|  Baane Mini Imports|                  1504|\n",
      "+--------------+--------------------+----------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = sqlContext \\\n",
    "    .read \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"url\", \"jdbc:mysql://localhost:3306/classicmodels\") \\\n",
    "    .option(\"driver\", \"com.mysql.cj.jdbc.Driver\") \\\n",
    "    .option(\"user\",\"root\") \\\n",
    "    .option(\"password\", \"QA2015!@#\") \\\n",
    "    .option(\"query\", \"SELECT customerNumber, customerName, salesRepEmployeeNumber FROM customers\") \\\n",
    "    .load()\n",
    "\n",
    "# Looks the schema of this DataFrame.\n",
    "df.printSchema()\n",
    "\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f05ea2",
   "metadata": {},
   "source": [
    "##### Save to MySQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e981120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.write\n",
    "#       .format(\"jdbc\") \\\n",
    "#     .option(\"url\", \"jdbc:mysql://localhost:3306/classicmodels\") \\\n",
    "#       .option(\"driver\", \"com.mysql.cj.jdbc.Driver\") \\\n",
    "#     .option(\"user\",\"root\") \\\n",
    "#     .option(\"password\", \"QA2015!@#\") \\\n",
    "#       .option(\"dbtable\", \"customers\") \\\n",
    "#   .save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
